{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13374d70-8acf-4e33-8f17-a7a2c2a5b3cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Description\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d702729-9967-4ba9-9907-df624c54ee59",
   "metadata": {},
   "source": [
    "We need a Google Cloud Platform project with billing enabled.</br>\n",
    "We first have to enable the `Cloud AI Platform Models API` and the `Compute Engine API`.</br>\n",
    "We then create an AI Platform Notebooks instance, then we select the latest `PyTorch` instance type (without/with ?????To determine?????? GPUs).</br>\n",
    "Once the instance has been created, we select `Open JupyterLab`:</br></br>\n",
    "After setting up the environment, we run the folling commands :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae4e516-5609-4723-8988-695538eb8364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsutil version: 5.6\n",
      "checksum: 0988591864f8c3a8ca1ae43f519e6d15 (OK)\n",
      "boto version: 2.49.0\n",
      "python version: 3.8.11 (default, Dec 23 2021, 04:09:42) [Clang 12.0.1 ]\n",
      "OS: Linux 4.19.0-18-cloud-amd64\n",
      "multiprocessing available: True\n",
      "using cloud sdk: True\n",
      "pass cloud sdk credentials to gsutil: True\n",
      "config path(s): /etc/boto.cfg\n",
      "gsutil path: /usr/lib/google-cloud-sdk/bin/gsutil\n",
      "compiled crcmod: True\n",
      "installed via package manager: False\n",
      "editable install: False\n"
     ]
    }
   ],
   "source": [
    "!gsutil version -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cab21971-3af9-41da-b267-271c0f75fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECT = 'My First Project'\n",
    "BUCKET_URL = 'gs://storage_bucket_speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8525f2-8170-447b-932c-eee595b00500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://storage_bucket_speech/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'storage_bucket_speech' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb $BUCKET_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ae68e-ac3b-4892-bfcd-5d24549dd9c4",
   "metadata": {},
   "source": [
    "The bucket already exists because it was already created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686886c1-04c2-4e8e-bc45-3ce23909f51a",
   "metadata": {},
   "source": [
    " Store the data on Google Storage\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7ec4275-26f6-4c5c-8859-a1eef1b9e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c7ab93b-3f55-43b9-9660-be9f1a51e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../feature-extraction/train/'\n",
    "test_path = '../feature-extraction/test/'\n",
    "valid_path = '../feature-extraction/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f23ab7-a227-4cd9-bc6c-1f32c883c48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp -r $train_path $BUCKET_URL\n",
    "!gsutil -m cp -r $test_path $BUCKET_URL\n",
    "!gsutil -m cp -r $valid_path $BUCKET_URL\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ac6938c-0f60-4dc6-892c-8659267ce5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.config import Config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f89da9f3-256c-4038-88e7-80c746e153f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.N_MELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a388f358-a908-48b0-82c4-ca201272c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch ./trainer/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698d442-8ef8-4c72-9adb-1aed3cf04468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4f885c-bd48-4a74-8d59-0f326be8a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ead070-4532-43b0-9762-b2cf4525b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging, json, pickle, argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda04a72-d739-4f5c-bbba-a0a218b436c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastavro\n",
      "  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastavro\n",
      "Successfully installed fastavro-1.4.10\n"
     ]
    }
   ],
   "source": [
    "!pip install fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc64576-39d0-49c1-b88c-00053dc52f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting avro\n",
      "  Downloading avro-1.11.0.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from avro) (4.1.1)\n",
      "Building wheels for collected packages: avro\n",
      "  Building wheel for avro (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro: filename=avro-1.11.0-py2.py3-none-any.whl size=115926 sha256=a4198cdf24d1ae6ba8f99c3f65cd8230c458c9653a6393aa770e19b49ea56d49\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/7d/79/ec/d7acfd56e9934b311783689c07ffecf6af9bde172950927f6d\n",
      "Successfully built avro\n",
      "Installing collected packages: avro\n",
      "Successfully installed avro-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "588ad682-d72f-430d-a9f0-037d50a9cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import avro.schema\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70dad76f-fcc0-42a9-8d7b-9d8ba98448a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1434139-c3b8-4b3b-93c0-7961252d6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\"namespace\": \"example.avro\",\n",
    " \"type\": \"record\",\n",
    " \"name\": \"User\",\n",
    " \"fields\": [\n",
    "     {\"name\": \"name\", \"type\": \"string\"},\n",
    "     {\"name\": \"favorite_number\",  \"type\": [\"int\", \"null\"]},\n",
    "     {\"name\": \"favorite_color\", \"type\": [\"string\", \"null\"]}\n",
    " ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc208917-fa60-4d14-ae5f-f152a41d48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = avro.schema.parse(json.dumps(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7827c7fb-b92e-4952-922b-5ecafbe283a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = DataFileWriter(open(\"users.avro\", \"wb\"), DatumWriter(), schema)\n",
    "writer.append({\"name\": \"Alyssa\", \"favorite_number\": 256})\n",
    "writer.append({\"name\": \"Ben\", \"favorite_number\": 7, \"favorite_color\": \"red\"})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0163b6e7-f7e0-4af0-81e5-d563ebfbaf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alyssa', 'favorite_number': 256, 'favorite_color': None}\n",
      "{'name': 'Ben', 'favorite_number': 7, 'favorite_color': 'red'}\n"
     ]
    }
   ],
   "source": [
    "reader = DataFileReader(open(\"users.avro\", \"rb\"), DatumReader())\n",
    "for user in reader:\n",
    "    print(user)\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b635167-7536-46e9-b65c-722cada4cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b88b5740-2b1f-42af-be98-c4d2d87dc3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://storage_bucket_speech/test'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(BUCKET_URL,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00837fcc-1fa2-45d3-b2aa-dc3a15a6a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "835086cf-0dc1-4175-9ce9-fec6e81a33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'tr'\n",
    "LOCAL_PATH = 'loc'\n",
    "\n",
    "if not os.path.exists(TRAIN_DATA_DIR):\n",
    "    os.mkdir(LOCAL_PATH)\n",
    "    \n",
    "if not os.path.exists(TRAIN_DATA_DIR):\n",
    "    os.mkdir(os.path.join(LOCAL_PATH, TRAIN_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc9d4383-b7e4-46b3-916d-5fc018c95d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac18431f-b0fa-4422-be04-ae21c572196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(download_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1cddb55-fc11-4c9c-93fa-b6c48bc44497",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = './test_dir'\n",
    "gcs_dir_path = 'gs://storage_bucket_speech/test/*.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2fc73a5-f646-4ba4-9153-391637c49162",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -q -m cp $gcs_dir_path $download_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7cbafb2-7633-46a5-99b7-a6fd07ba61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rr:\n",
    "    \n",
    "    BUCKET_URL = 'gs://storage_bucket_speech'\n",
    "    TRAIN_DIR  = ''\n",
    "    VALID_DIR  = ''\n",
    "    TEST_DIR   = ''\n",
    "    \n",
    "    #Model parameters :\n",
    "    N_MELS              = 128\n",
    "    INPUT_SPEC_SIZE     = 3 * N_MELS\n",
    "    RNN_CELL            = 'lstm' # 'lstm' | 'gru'\n",
    "    CNN_FILTER_SIZE     = 64\n",
    "    \n",
    "    NUM_GENDER_CLASSES  = 2\n",
    "    NUM_EMOTION_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5db3a901-32ec-498c-9067-fbf02260a44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.CNN_FILTER_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4331007c-8e84-4eec-a9b4-9053bd652bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d47406e-a1d7-4149-aa0a-5c15ce2de471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3daeefd-8d03-40b7-a614-3c5545d60316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e4b80d1-f4ce-48aa-ae3c-5adf7dc17673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b08d552-bc93-4924-8556-5ccdee7f516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3298a8-dda2-4b43-8ce7-fa77877e385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, pckl_dir):\n",
    "        self.pckl_dir = pckl_dir\n",
    "        self.pckl_files = os.listdir(self.pckl_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pckl_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.pckl_files[index]\n",
    "        with open(os.path.join(self.pckl_dir, filename), 'rb') as handle:\n",
    "            data = pickle.load(handle)\n",
    "\n",
    "        feature = data['feature']\n",
    "        emotion_idx = data['emotion']\n",
    "        gender_idx = data['gender']\n",
    "        length = feature.shape[-1]\n",
    "\n",
    "        return feature, length, emotion_idx, gender_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9903bd6-9981-4316-be66-53f3f509713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "      Creates mini-batch tensors from the list \n",
    "      of tuples (feature, length, emotion_idx, gender_idx)\n",
    "    \"\"\"\n",
    "\n",
    "    #sort in descending order\n",
    "    batch.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #from list of tuples to tuple of lists\n",
    "    features, lengths, emotion_idxs, gender_idxs = zip(*batch)\n",
    "\n",
    "    batch_size, num_channels, spec_dimension, temporal_length = len(features), 1, 128*3, max(lengths)\n",
    "    padded_features = torch.zeros(batch_size, num_channels, spec_dimension, temporal_length)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        padded_features[i] = F.pad(feature, (0, max(lengths) - lengths[i]))\n",
    "\n",
    "    return padded_features, torch.tensor(lengths), torch.tensor(emotion_idxs), torch.tensor(gender_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5379d4e6-3d1e-4044-833b-918dc2c6c6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__pycache__\t\textractFeaturesTrain.py   ravdess\n",
      "_noise\t\t\tfeature_extraction.ipynb  test\n",
      "_rir\t\t\tinstall-requirements.sh   timefreaMasking.py\n",
      "config.py\t\trandomBackgroundNoise.py  train\n",
      "extractFeaturesTest.py\trandomSpeedChange.py\t  valid\n"
     ]
    }
   ],
   "source": [
    "!ls ../feature-extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f603c4-c47b-48d6-bb66-28bb94c1aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pck_dir = '../feature-extraction/test'\n",
    "dataset_test  = Dataset(test_pck_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1d74a5e-c430-4e7a-88c7-4d17caba2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test  = DataLoader(dataset=dataset_test,  batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3439cd56-0038-450c-b174-99255cf31633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.4448e-11,  1.1669e-07,  2.0860e-07,  ...,  5.8384e-10,\n",
       "            1.8503e-09,  1.1795e-07],\n",
       "          [ 1.6174e-11,  1.0900e-07,  1.9478e-07,  ...,  5.3275e-10,\n",
       "            1.3788e-09,  9.7088e-08],\n",
       "          [ 3.3241e-12,  1.0023e-07,  1.7900e-07,  ...,  4.6804e-10,\n",
       "            6.6201e-10,  6.6597e-08],\n",
       "          ...,\n",
       "          [ 6.5888e-12, -4.4600e-12, -3.1279e-11,  ...,  3.4144e-11,\n",
       "            1.1921e-11,  6.1038e-12],\n",
       "          [ 2.7159e-12, -1.0641e-11, -3.0324e-11,  ...,  4.5902e-11,\n",
       "            2.7055e-11,  1.0103e-11],\n",
       "          [-8.5276e-13, -4.0894e-12, -1.2229e-11,  ...,  1.9280e-11,\n",
       "            1.0041e-11,  8.5196e-12]]]),\n",
       " 183,\n",
       " 8,\n",
       " 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_test.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aff9d03b-dbd4-448f-87c3-1cefceb230d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_test.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cbb5d78-e7e7-43c1-a336-82eb7f5780b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if (True and True and\n",
    "     True):\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efe793b9-870e-4859-ad15-3d8ad46b0f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  config.py\t experiment.py\ttask.py\n",
      "__pycache__  dataset.py  model.py\tutils.py\n"
     ]
    }
   ],
   "source": [
    "!ls trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "650f6ca4-bedf-4f6d-9759-6a03590319f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from trainer.config import Config as cfg\n",
    "    \n",
    "class Speech2Emotion(nn.Module):\n",
    "    def __init__(self, input_spec_size=cfg.INPUT_SPEC_SIZE, cnn_filter_size=cfg.CNN_FILTER_SIZE, lstm_hidden_size=128, num_layers_lstm=2,\n",
    "                 dropout_p=0.2, bidirectional=True, rnn_cell=cfg.RNN_CELL, num_gender_class=cfg.NUM_GENDER_CLASSES,\n",
    "                 num_emotion_classes=cfg.NUM_EMOTION_CLASSES):\n",
    "            \n",
    "        super(Speech2Emotion, self).__init__()\n",
    "        self.input_spec_size = input_spec_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers_lstm = num_layers_lstm\n",
    "        self.dropout_p = dropout_p\n",
    "        self.num_emo_classes = num_emotion_classes\n",
    "        self.num_gender_class = num_gender_class\n",
    "        self.cnn_filter_size = cnn_filter_size\n",
    "        \n",
    "        if rnn_cell.lower() == 'lstm':\n",
    "            self.rnn_cell = nn.LSTM\n",
    "        elif rnn_cell.lower() == 'gru':\n",
    "            self.rnn_cell = nn.GRU\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN Cell: {0}\".format(rnn_cell))\n",
    "            \n",
    "    \n",
    "        outputs_channel = self.cnn_filter_size\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, outputs_channel, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(outputs_channel),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(outputs_channel, outputs_channel, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(outputs_channel),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ))\n",
    "        \n",
    "        rnn_input_dims = int(math.floor(input_spec_size + 2 * 20 - 41) / 2 + 1)\n",
    "        rnn_input_dims = int(math.floor(rnn_input_dims + 2 * 10 - 21) / 2 + 1)\n",
    "        rnn_input_dims *= outputs_channel\n",
    "\n",
    "        self.rnn =  self.rnn_cell(rnn_input_dims, self.lstm_hidden_size,\n",
    "                                  self.num_layers_lstm, dropout=self.dropout_p, bidirectional=self.bidirectional)\n",
    "        self.self_attn_layer = nn.TransformerEncoderLayer(d_model=self.lstm_hidden_size*2, dim_feedforward=512,nhead=8)\n",
    "        self.gender_layer  = nn.Linear(self.lstm_hidden_size*4, self.num_gender_class)\n",
    "        self.emotion_layer = nn.Linear(self.lstm_hidden_size*4, self.num_emo_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, input_var, input_lengths=None):\n",
    "        output_lengths = self.get_seq_lens(input_lengths)\n",
    "        x = input_var # (B,1,D,T)\n",
    "        x, _ = self.conv(x, output_lengths) # (B, C, D, T)\n",
    "        \n",
    "        x_size = x.size()\n",
    "        x = x.view(x_size[0], x_size[1] * x_size[2], x_size[3]) # (B, C * D, T)\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous() # (T, B, D)\n",
    "        \n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, output_lengths, enforce_sorted=True)\n",
    "        x, h_state = self.rnn(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x)\n",
    "        \n",
    "        x = x.transpose(0, 1) # (B, T, D)\n",
    "        \n",
    "        x = self.self_attn_layer(x)\n",
    "        \n",
    "        mu = torch.mean(x, dim=1)\n",
    "        std = torch.std(x, dim=1)\n",
    "        pooled = torch.cat((mu,std),dim=1)\n",
    "        \n",
    "        gen_pred = self.gender_layer(pooled)\n",
    "        emo_pred = self.emotion_layer(pooled)\n",
    "        \n",
    "        return emo_pred, gen_pred\n",
    "\n",
    "    def get_seq_lens(self, input_lengths):\n",
    "        seq_len = input_lengths\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d :\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "\n",
    "        return seq_len.int()\n",
    "    \n",
    "class MaskConv(nn.Module):\n",
    "    def __init__(self, seq_module):\n",
    "        super(MaskConv, self).__init__()\n",
    "        self.seq_module = seq_module\n",
    "\n",
    "    def forward(self, x, lengths): #(B,1,D,T)\n",
    "        for module in self.seq_module:\n",
    "            x = module(x)\n",
    "            mask = torch.BoolTensor(x.size()).fill_(0)\n",
    "            if x.is_cuda:\n",
    "                mask = mask.cuda()\n",
    "            for i, length in enumerate(lengths):\n",
    "                length = length.item()\n",
    "                if (mask[i].size(2) - length) > 0:\n",
    "                    mask[i].narrow(2, length, mask[i].size(2) - length).fill_(1)\n",
    "            x = x.masked_fill(mask, 0)\n",
    "        return x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d652d78-3f17-4866-a9f3-937495841dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Speech2Emotion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7d56f8a-4b0c-4684-86c7-8df83b0d97ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "289342c8-a88e-4ff3-b5bc-3ab4640812ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TENSORBOARD_LOG_DIR'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'tensorboard_log_dir'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5eab34e6-cae0-4365-8313-c94bedab56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('tmp', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24338525-8baf-4f6d-8e39-4da23edc876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "838480d5-1781-483e-9675-e783e459cf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir1 = 'log'\n",
    "local_model_dir = './tmp/model'\n",
    "\n",
    "model_dir = model_dir1 or local_model_dir\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "240bdfc6-4cdd-4e61-abd9-8fd1441a969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This is a warning message\n",
      "ERROR:root:This is an error message\n",
      "CRITICAL:root:This is a critical message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.debug('This is a debug message')\n",
    "logging.info('This is an info message')\n",
    "logging.warning('This is a warning message')\n",
    "logging.error('This is an error message')\n",
    "logging.critical('This is a critical message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9d19966-e976-45df-ac86-de78988da2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:2022-03-07 00:46:54,906] info log\n",
      "INFO:mylogger:info log\n"
     ]
    }
   ],
   "source": [
    "import logging.config\n",
    "\n",
    "MY_LOGGING_CONFIG = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'formatters': {\n",
    "        'default_formatter': {\n",
    "            'format': '[%(levelname)s:%(asctime)s] %(message)s'\n",
    "        },\n",
    "    },\n",
    "    'handlers': {\n",
    "        'stream_handler': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'formatter': 'default_formatter',\n",
    "        },\n",
    "    },\n",
    "    'loggers': {\n",
    "        'mylogger': {\n",
    "            'handlers': ['stream_handler'],\n",
    "            'level': 'INFO',\n",
    "            'propagate': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(MY_LOGGING_CONFIG)\n",
    "logger = logging.getLogger('mylogger')\n",
    "logger.info('info log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "faa8c0ca-dcb3-41d4-888a-b337ed15d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Hello World\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)  \n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "file_handler = logging.FileHandler('logs/sample.log')\n",
    "formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c2277e2-44f7-4ec0-b2ab-c5711b3f31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcc5e297-8f8d-4ca9-acb7-49156042050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('lo')\n",
    "if not os.path.exists(os.path.join('lo', 'gh')):\n",
    "    print('g')\n",
    "    os.mkdir(os.path.join('lo', 'gh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78dbe9-c915-453b-87d5-3f45dba5ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('g \\n g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094d6ad-d935-4ac9-932d-e33b04c8c361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
